# ğŸ™ï¸ 30 Days of AI Voice Agents â€“ Murf AI Challenge

An interactive voice-based chatbot powered by **FastAPI**, **Murf TTS**, **AssemblyAI Speech-to-Text**, and **Google Gemini LLM**.  
This project lets you talk to an AI agent using your microphone, transcribes your speech, processes it via Gemini, and replies with natural-sounding speech.

---

## ğŸš€ Features

- **ğŸ¤ Real-time Voice Recording** â€“ Record directly from the browser
- **ğŸ—£ï¸ Speech-to-Text (STT)** â€“ Uses AssemblyAI to transcribe speech
- **ğŸ§  LLM Responses** â€“ Processes messages using Google Gemini
- **ğŸ”Š Text-to-Speech (TTS)** â€“ Uses Murf API to generate lifelike audio responses
- **ğŸ’¬ Chat History** â€“ Keeps multi-turn conversation context
- **âš ï¸ Error Handling** â€“ Plays fallback audio in case of API failure
- **ğŸ“± Clean UI** â€“ HTML + CSS with animated buttons and chat bubbles

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.9+**
- **FastAPI** â€“ API framework
- **Jinja2** â€“ Template rendering
- **httpx** â€“ Async HTTP calls to APIs

### Frontend
- **Vanilla JavaScript**
- **HTML5 & CSS3**
- **Fetch API** â€“ Send audio data & receive AI responses

### AI & APIs
- **Murf API** â€“ Text-to-Speech
- **AssemblyAI API** â€“ Speech-to-Text
- **Google Gemini API** â€“ AI chat responses

---

## ğŸ—ï¸ Architecture Overview

1. **User clicks record** â†’ Microphone input captured via `MediaRecorder API`
2. Audio blob sent to **FastAPI backend** (`/process-audio`)
3. Backend sends audio to **AssemblyAI** â†’ gets transcribed text
4. Transcribed text sent to **Gemini LLM** â†’ gets AI response
5. Response text sent to **Murf API** â†’ gets generated speech
6. Audio + text sent back to frontend â†’ displayed in chat + played in browser

---

## ğŸ“¦ Installation & Setup

### 1ï¸âƒ£ Clone this repository
- git clone https://github.com/yourusername/murf-ai-challenge.git
- cd murf-ai-challenge

### 2ï¸âƒ£ Create a virtual environment & install dependencies
- python -m venv venv
- source venv/bin/activate  # macOS/Linux
- venv\Scripts\activate     # Windows

- pip install -r requirements.txt

### 3ï¸âƒ£ Set up Environment Variables
- Create a .env file in the root directory and add:
- MURF_API_KEY=your_murf_api_key
- ASSEMBLYAI_API_KEY=your_assemblyai_api_key
- GEMINI_API_KEY=your_gemini_api_key

### 4ï¸âƒ£ Run the FastAPI server
- uvicorn main:app --reload
- The app will be available at:
- â¡ï¸ http://127.0.0.1:8000

### 5ï¸âƒ£ Open the app in your browser
- Go to the above link and start chatting ğŸ§

---
### ğŸ“¸ Screenshots
- <img width="2239" height="1194" alt="Screenshot 2025-08-14 095416" src="https://github.com/user-attachments/assets/544f7f76-c580-43cf-a2be-3539a71cdaec" />



---
### ğŸ“œ License
- This project is licensed under the MIT License â€“ see the LICENSE file for details.

---
### ğŸŒŸ Acknowledgements
- Murf AI for lifelike TTS
- AssemblyAI for powerful STT
- Google Gemini for conversational intelligence
- FastAPI for backend magic
